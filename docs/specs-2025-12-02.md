# **Curva Quiz — Structured Summary (Quiz-Only Content)**

## 1. Project status & backend architecture

* You mentioned you **haven’t progressed much since the previous call**, but:

  * You **started implementing server-side state validation** using **Cloudflare Durable Objects**, aligned with the long-term vision.
  * The idea is that **the server (not the client) validates state changes**, so you can:

    * Make the backend more robust.
    * **Intercept any unauthorized or invalid modifications of answers**.
* You plan to **restructure this implementation** to get a cleaner architecture and stronger guarantees around state and cheating prevention.

**Key takeaway:**
CurvaQuizz is moving toward a **Durable-Object-centric backend**, where all game state transitions (answers, score, progression) will be validated and enforced server-side.

---

## 2. Game configuration: number of questions

* Wandrille asked if you could **increase the number of questions per quiz from 5 to 10**, as previously discussed.
* You confirmed it’s **trivial to do**:

  * It’s controlled by a **single parameter**, likely an **environment variable**.
  * So the **game length is configurable** without code changes.

**Key takeaway:**
CurvaQuizz’s quiz length is already parameterized — going from **5 to 10 questions** is just a config change.

---

## 3. Using RAG / embeddings for CurvaQuizz

Even though the RAG discussion was broad, there *were* specific links to CurvaQuizz.

### 3.1. Initial idea (from Wandrille)

* Wandrille suggested that **RAG (Retrieval-Augmented Generation)** could be:

  * A **great system to generate quiz content**, especially:

    * To structure match data.
    * To extract **interesting facts** from matches.
  * Essentially: use RAG to mine football information and turn it into good questions.

### 3.2. Clarification of how RAG would actually help CurvaQuizz

* You clarified that **RAG doesn’t work exactly as Wandrille first imagined**, but could still be very useful:

  * You could **store embeddings + summaries of each match**.
  * Then you can ask complex questions like:

    * “Find unusual facts about this match.”
    * “What was special about [team] vs [team]?”
  * The RAG would query **match summaries** and **supporting facts**, which can then be turned into quiz questions.

### 3.3. Cost & scalability angle (relevant for CurvaQuizz as a product)

* You both noted that:

  * A RAG-based system could become **a powerful alternative to expensive sports stats APIs**, which cost **2–5k €/month**.
  * Embeddings are **cheap to generate and store**, especially with Google-style pricing (cited ~0.15$/M tokens).
  * Querying embeddings is cheaper than hammering a big LLM for everything.

**Key takeaway:**
There’s a **clear technical direction** where CurvaQuizz could:

* **Ingest match reports / stats**, generate embeddings, and store them.
* Use RAG to **discover interesting angles and facts** for quiz questions.
* Potentially **replace or complement premium sports data APIs** at a much lower cost.

---

## 4. Implicit next steps for CurvaQuizz

Not explicitly framed as “action items” in the meeting, but they’re implied:

1. **Backend / Durable Objects**

   * Restructure the Durable Objects implementation so that:

     * All state transitions (answers, progression, scoring) go through them.
     * They **enforce validation** and **protect against tampering**.

2. **Game design**

   * Switch config to **10 questions per quiz** (or make this easily adjustable per competition / format).

3. **AI / RAG exploration (for future versions)**

   * Define a pipeline to:

     * Ingest match summaries / stats.
     * Generate embeddings and store them.
     * Experiment with **RAG-powered question generation**:

       * “What was unusual in this match?”
       * “Which stat was surprising given the final score?”
   * Compare this to buying / using **traditional sports APIs**.
